1、git clone https://github.com/THUDM/GLM-4.git
2、pip install -r requirements.txt
3、model: git clone https://huggingface.co/THUDM/glm-4-9b-chat-hf
4、modelscope也一样：git clone https://www.modelscope.cn/ZhipuAI/glm-4-9b-chat-hf.git
5、/project/GLM-4-main/basic_demo/trans_cli_demo.py  #改model地址
6、python3 ./trans_cli_demo.py

量化4bit
glm3:
model_name_or_path="/home/egcs/models/chatglm3-6b"
model=AutoModel.from-pretrained(model_name_or_path,trust_remote_code=True).quantize(4).cuda()
glm4:
model_name_or_path="/home/egcs/models/glm4-9b-chat"
model=AutoModelForCausalLm.from_pretrained(
model_name_or_path,
low_cpu_mem_usage=True,
trust_remote_code=True,
load_in_4bit=True
).eval()


中文分词
分词方法：
词典、统计(Hidden Markov Model HMM)、规则、deeplearn
工具：
Jieba、THULAC、哈工大LTP （HMM、条件随机场Conditional Random Field CRF）、NLPIR、斯坦福分词器


JAX python库






